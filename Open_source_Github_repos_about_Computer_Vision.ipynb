{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Open-source Github repos about Computer Vision.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khoinguyen-hvkn/MaSSP/blob/master/Open_source_Github_repos_about_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtYrWj2GMfj4",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "This note lists open source github repos for computer vision and speech recognition, which can be used as useful tools for the final projects in MaSSP19\n",
        "* Computer vision: object detection, facial recognition, scene parsing, segmentation\n",
        "* Image processing: super resolution, colorization\n",
        "* Speech recognition: google speech recognition API (English only)\n",
        "\n",
        "The repos below are sorted by topics, frameworks, and difficulty. For difficulty, we mean the difficulty in using the repos training and inference. Concretely, `easy` means the repo can be used directly and easily, in inference and training (if needed), `medium` means that we have to read the code and modify the code a little bit to get our desired results, and `hard` means that we have to carry out many additional tasks (e.g. data prepration, installation, etc.) in order to use the code properly.\n",
        "\n",
        "# Open source Github repos for MaSSP projects\n",
        "## Basic repos\n",
        "**Image classifications**:\n",
        "* Keras applications: https://keras.io/applications/\n",
        "    * *Topics*: `image classification`, `basic`\n",
        "    * *Frameworks*: `Keras`\n",
        "    * *Difficulty*: `easy`\n",
        "* EfficientNet: https://github.com/titu1994/keras-efficientnets\n",
        "    * *Topics*: `image classification`\n",
        "    * *Frameworks*: `Keras`\n",
        "    * *Difficulty*: `easy`\n",
        "* Other models: https://github.com/qubvel/classification_models\n",
        "    * *Topics*: `image classification`\n",
        "    * *Frameworks*: `Keras`, `MXNet` (optional), `PyTorch` (optional)\n",
        "    * *Difficulty*: `easy`\n",
        "\n",
        "**Object detection**:\n",
        "* RetinaNet: https://github.com/fizyr/keras-retinanet\n",
        "    * *Topics*: `object detection`\n",
        "    * *Frameworks*: `Keras`\n",
        "    * *Difficulty*: `medium`\n",
        "    * *Reference*: https://towardsdatascience.com/review-retinanet-focal-loss-object-detection-38fba6afabe4\n",
        "    * *Example*: https://vn-zoom.org/threads/tu-viet-cong-cu-nhan-dang-hinh-anh-don-gian-bang-python.11929\n",
        "* YOLOv3: https://github.com/qqwweee/keras-yolo3\n",
        "    * *Topics*: `object detection`\n",
        "    * *Frameworks*: `Keras`\n",
        "    * *Difficulty*: `medium`\n",
        "\n",
        "**Semantic segmentation**:\n",
        "* Deeplab: https://github.com/tensorflow/models/tree/master/research/deeplab\n",
        "    * *Topics*: `semantic segmentation`\n",
        "    * *Frameworks*: `TensorFlow`\n",
        "    * *Difficulty*: `hard`\n",
        "* Fast SCNN: https://github.com/Tramac/Fast-SCNN-pytorch\n",
        "    * *Topics*: `semantic segmentation`\n",
        "    * *Frameworks*: `PyTorch`\n",
        "    * *Difficulty*: `hard`\n",
        "* U-Net: https://github.com/zhixuhao/unet\n",
        "    * *Topics*: `semantic segmentation`\n",
        "    * *Frameworks*: `Keras`\n",
        "    * *Difficulty*: `easy`\n",
        "* PSP: https://github.com/Kautenja/keras-pyramid-pooling-module\n",
        "    * *Topics*: `semantic segmentation`\n",
        "    * *Frameworks*: `Keras`\n",
        "    * *Difficulty*: `easy`\n",
        "* Other models: https://github.com/qubvel/segmentation_models\n",
        "    * *Topics*: `semantic segmentation`\n",
        "    * *Frameworks*: `Keras`\n",
        "    * *Difficulty*: `easy`\n",
        "\n",
        "## Human-related repos\n",
        "**Face-related**:\n",
        "* InsightFace: https://github.com/deepinsight/insightface\n",
        "    * *Topics*: `facial recognition`, `face detection`, `face landmarks`\n",
        "    * *Frameworks*: `MXNet`\n",
        "    * *Difficulty*: `medium`\n",
        "* Facial-recognition: https://github.com/ageitgey/face_recognition\n",
        "    * *Topics*: `facial recognition`, `face detection`, `face landmarks`\n",
        "    * *Frameworks*: `Dlib`\n",
        "    * *Difficulty*: `easy`  \n",
        "* Face orientation: https://github.com/shamangary/FSA-Net\n",
        "    * *Topics*: `face orientation`\n",
        "    * *Frameworks*: `Keras`\n",
        "    * *Difficulty*: `medium`  \n",
        "\n",
        "**Pose estimation**:\n",
        "* OpenPose: https://github.com/CMU-Perceptual-Computing-Lab/openpose\n",
        "    * *Topics*: `pose estimation`\n",
        "    * *Frameworks*: `caffe`, `opencv`\n",
        "    * *Difficulty*: `medium`\n",
        "    * *Reference*: https://deeplearning.vn/post/openpose\n",
        "    * *Example*: https://colab.research.google.com/github/tugstugi/dl-colab-notebooks/blob/master/notebooks/OpenPose.ipynb\n",
        "\n",
        "## Image pre-processing repos\n",
        "**Image colorization**:\n",
        "* Colorization: https://github.com/richzhang/colorization\n",
        "    * *Topics*: `colorization`\n",
        "    * *Frameworks*: `caffe`\n",
        "    * *Difficulty*: `medium`\n",
        "\n",
        "**Super-resolution**: \n",
        "* ESRGAN: https://github.com/xinntao/ESRGAN\n",
        "    * *Topics*: `super resolution`\n",
        "    * *Frameworks*: `PyTorch``\n",
        "    * *Difficulty*: `medium`\n",
        "\n",
        "**Image data augmentation**: \n",
        "* Augmentor: https://github.com/mdbloice/Augmentor\n",
        "    * *Topics*: `image data augmentation`\n",
        "    * *Frameworks*: \n",
        "    * *Difficulty*: `easy`\n",
        "* Imgaug: https://github.com/aleju/imgaug\n",
        "    * *Topics*: `image data augmentation`\n",
        "    * *Frameworks*: \n",
        "    * *Difficulty*: `easy`\n",
        "\n",
        "## NLP\n",
        "**Speech recognition**:\n",
        "* Speech_recognition API: https://pypi.org/project/SpeechRecognition/\n",
        "    * *Topics*: `speech recognition`, `speech-to-text`\n",
        "    * *Frameworks*: \n",
        "    * *Difficulty*: `easy\n",
        "\n",
        "**OCR**:\n",
        "* Tesseract: https://www.pyimagesearch.com/2017/07/10/using-tesseract-ocr-python/\n",
        "    * *Topics*: `ocr`\n",
        "    * *Frameworks*: \n",
        "    * *Difficulty*: `easy\n",
        "* Others: https://github.com/kba/awesome-ocr\n",
        "\n",
        "**Question answering**:\n",
        "* Deep Pavlov: https://github.com/deepmipt/DeepPavlov\n",
        "    * *Topics*: `question answering`, `sentence similarity`, `named entity recognition`, `slot filling`, `tf-idf ranking`, `morphological tagging`, `automatic spelling correction`\n",
        "    * *Frameworks*: \n",
        "    * *Difficulty*: `easy\n",
        "\n",
        "**Sentence similarity ranking**: \n",
        "* Deep Pavlov: https://github.com/deepmipt/DeepPavlov\n",
        "\n",
        "**Named entity recognition**:\n",
        "* Deep Pavlov: https://github.com/deepmipt/DeepPavlov\n",
        "\n",
        "**Slot filling**:\n",
        "* Deep Pavlov: https://github.com/deepmipt/DeepPavlov\n",
        "\n",
        "**TF-IDF ranking**:\n",
        "* Deep Pavlov: https://github.com/deepmipt/DeepPavlov\n",
        "\n",
        "**Morphological tagging**:\n",
        "* Deep Pavlov: https://github.com/deepmipt/DeepPavlov\n",
        "\n",
        "**Automatic spelling correction**:\n",
        "* Deep Pavlov: https://github.com/deepmipt/DeepPavlov\n",
        "\n",
        "## Problem-specific repos\n",
        "**Detect-and-Track: Efficient Pose Estimation in Videos**: https://github.com/facebookresearch/DetectAndTrack\n",
        "* *Topics*: `pose estimation`, `human tracking`\n",
        "* *Frameworks*: `caffe`, `opencv`\n",
        "* *Difficulty*: `hard`\n",
        "\n",
        "**Detectron**: https://github.com/facebookresearch/Detectron\n",
        "* *Topics*: `object detection`, `semantic segmentation`\n",
        "* *Frameworks*: \n",
        "* *Difficulty*: `hard`\n",
        "\n",
        "**Anomaly detection in video**: https://github.com/WaqasSultani/AnomalyDetectionCVPR2018\n",
        "* *Topics*: `anomaly detection`\n",
        "* *Frameworks*: `Keras`, `Theano`\n",
        "* *Difficulty*: `medium`\n",
        "\n",
        "## Other resources\n",
        "**Other colabs**: https://github.com/tugstugi/dl-colab-notebooks\n",
        "\n",
        "**RecSys for books, movies recommendation among MaSSP mentees**\n",
        "\n",
        "**Face recognition.**: https://github.com/topics/face-recognition?o=desc&s=stars\n",
        "\n",
        "**OpenAI GPT-2**: https://talktotransformer.com\n",
        "\n",
        "**Vehicle detection with YOLO pretrain**: https://github.com/thangnch/yolo_beginner\n",
        "* Darknet:\n",
        "    * THTrieu's Darkflow: https://github.com/thtrieu/darkflow/\n",
        "    * AlexBey's Darknet YOLO v.3: https://github.com/AlexeyAB/darknet \n",
        "\n",
        "**EfficientNet for flowers**: https://colab.research.google.com/drive/1JmmS_mhSITi5quyvFzmFZvsblMHOp5ll\n",
        "\n",
        "**Deep Learning: Zero2All**: https://github.com/hunkim/DeepLearningZeroToAll"
      ]
    }
  ]
}