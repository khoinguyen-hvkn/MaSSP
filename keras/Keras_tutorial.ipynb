{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khoinguyen-hvkn/MaSSP/blob/master/keras/Keras_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkX8CNmqTusc",
        "colab_type": "text"
      },
      "source": [
        "# GIỚI THIỆU VỀ KERAS\n",
        "## Keras là gì ?\n",
        "[Keras](https://keras.io/) là một deep learning framework dựa trên backend là Theano, TensorFlow và CNTK (ba deep learning framework rất nổi tiếng hiện nay). Nói cách khác, các class và functions trong Keras được viết bằng TensorFlow, Theano và CNTK.\n",
        "\n",
        "## Ưu điểm của Keras\n",
        "Keras có thể được coi là một high-level framework. Nó cho phép chúng ta tạo ra các deep learning models một cách dễ dàng hơn rất nhiều so với các frameworks như TensorFlow, Theano, etc\n",
        "\n",
        "## Nhược điểm của Keras\n",
        "Keras là một high-level framework, chính vì thế nếu ta muốn can thiệp sâu vào phần low-level (VD: tự viết một thuật toán tối ưu cho model) thì Keras tỏ ra kém hiệu quả so với các frameworks như TensorFlow\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpUkoZqiVs4D",
        "colab_type": "text"
      },
      "source": [
        "# CÁC CORE LAYERS TRONG KERAS\n",
        "Chúng ta sẽ bắt đầu với loại layer cơ bản nhất trong deep learning - Dense layer. Sau đó sẽ nói về các layer phức tạp hơn.\n",
        "\n",
        "> **LƯU Ý**: muốn khởi tạo một layer trong Keras, ta cần import layer đó trước"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2AHmyBOWK5L",
        "colab_type": "text"
      },
      "source": [
        "## Dense\n",
        " ### Fully-connected neural net layer (Dense layer)\n",
        "Kiểu layer cơ bản nhất trong deep learning, với các neurons được tổ chức thành một vector một chiều. Một neuron trong một Dense layer sẽ được kết nối với tất cả neurons thuộc layer liền trước và layer liền sau.\n",
        "\n",
        "Dưới đây là một neural network với Input, Output và Hidden layers đều là Dense layers (Lưu ý: Input layer ở đây thực chất là Dense layer, nhưng trong Keras sẽ sử dụng một kiểu layer khác chuyên để biểu diễn Input layer)\n",
        "![Dense layer example](https://machinelearningcoban.com/assets/14_mlp/multi_layers.png =500x350)\n",
        "\n",
        "(Ảnh lấy từ [blog của anh Tiệp](https://machinelearningcoban.com/2017/02/24/mlp/))\n",
        "\n",
        "### Khai báo một Dense layer\n",
        "\n",
        "Trước hết, ta hãy xem đoạn code khai báo Dense layer như sau:\n",
        "\n",
        "```\n",
        "# import layer từ Keras\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Dòng lệnh này sẽ trả về một Keras Layer\n",
        "layer = Dense(\n",
        "    units=5, \n",
        "    activation='relu',\n",
        "    name='layer_1'\n",
        ")\n",
        "\n",
        "# Dòng lệnh này sẽ trả về một Keras Tensor\n",
        "cur_output = Dense(\n",
        "    units=5,\n",
        "    activation='relu',\n",
        "    name='layer_1'\n",
        ")(prev_output)\n",
        "```\n",
        "\n",
        "**Package keras.layers**: mọi pre-defined layers trong Keras đều thuộc package **keras.layers**\n",
        "\n",
        "**Keras Tensor và Keras Layer**: lấy ví dụ đơn giản một dense layer trong Deep learning như sau:\n",
        "\n",
        "$\\hspace{1.0cm} a = g(W^Tx + b)$\n",
        "\n",
        "Ta có thể thẩy, đối với layer trên thì \n",
        "\n",
        "$\\hspace{1.0cm} x$ là output của layer liền trước layer đang xét\n",
        "\n",
        "$\\hspace{1.0cm} a$ là output của layer đang xét\n",
        "\n",
        "$\\hspace{1.0cm} g$ là activation function của layer đang xét (cho bạn nào quên)\n",
        "\n",
        "$\\hspace{1.0cm} W, b$ là weights và bias của layer đang xét (cho bạn nào quên)\n",
        "\n",
        "Trong Keras, $a$ và $x$ chính là các **Tensors** còn cấu trúc $a = g(W^Tx + b)$ chính là **Layer**.\n",
        "> **LƯU Ý**: trong Keras, *weights* (tức $W$ ở ví dụ trên) còn được gọi là *kernel*. Riêng *bias*  (tức $b$ ở ví dụ trên) thì vẫn được gọi là *bias*\n",
        "\n",
        "> **Nâng cao**: tên gọi Tensor thực chất bắt nguồn từ khái niệm *Tensor* trong toán học (một mảng $n$ chiều với $n$ có thể lớn hơn 2)\n",
        "  * $n = 1$ thì Tensor được gọi là Vector\n",
        "  * $n = 2$ thì Tensor được gọi là Matrix (ma trận)\n",
        "\n",
        "**Phân tích cú pháp khai báo**:\n",
        "\n",
        "* **Cú pháp 1**:\n",
        "```\n",
        "# Dòng lệnh này sẽ trả về một Keras Layer\n",
        "layer = Dense(\n",
        "    units=5, \n",
        "    activation='relu',\n",
        "    name='layer_1'\n",
        ")\n",
        "```\n",
        "Cú pháp này sẽ trả về một Keras Layer với số neurons là 5, activation function là hàm ReLU và tên của layer là 'layer_1'\n",
        "\n",
        "* **Cú pháp 2**:\n",
        "```\n",
        "# Dòng lệnh này sẽ trả về một Keras Tensor\n",
        "cur_output = Dense(\n",
        "    units=5,\n",
        "    activation='relu',\n",
        "    name='layer_1'\n",
        ")(prev_output)\n",
        "```\n",
        "Cú pháp này sẽ trả về một Keras Tensor với các thuộc tính tương tự như cú pháp 1. Để dễ hiểu, nếu ta muốn khai báo layer $a = g(W^Tx + b)$ làm ví dụ thì\n",
        "\n",
        "$\\hspace{1.0cm}$ cur_output là $a$ \n",
        "\n",
        "$\\hspace{1.0cm}$ prev_output là $x$\n",
        "\n",
        "$\\hspace{1.0cm}$ units là số phần tử trong vector $x$\n",
        "\n",
        "$\\hspace{1.0cm}$ activation là $g$\n",
        "\n",
        "**?**: có thể các em sẽ thắc mắc tại cách khai báo 1 không khai báo layer liền trước của layer đang xét ? Như vậy thì làm sao có thể build được model dựa trên cách khai báo này ? Rõ ràng cách khai báo 1 chỉ khai báo 1 layer độc lập mà không thuộc một model nào đúng không ? Hãy đọc tiếp nhé, các em sẽ biết cách tạo model bằng cách khai báo 1.\n",
        "\n",
        "### Input và output của một Dense layer\n",
        "**Input**: input của một Dense layer trong Keras phải là một Tensor n chiều có dạng (n_samples, prev_layer_shape[1], ..., prev_layer_shape[n])\n",
        "  * Lấy Input Tensor của một Keras Layer:\n",
        "  ```\n",
        "  layer.input\n",
        "  ```\n",
        "  * Lấy Input shape của một Keras Layer:\n",
        "  ```\n",
        "  layer.input_shape\n",
        "  ```\n",
        "\n",
        "**Output**: output của một Dense layer trong Keras là một Tensor m chiều có dạng (n_samples, cur_layer_shape[1], ..., cur_layer_shape[m])\n",
        "  * Lấy Output Tensor của một Keras Layer:\n",
        "  ```\n",
        "  layer.output\n",
        "  ```\n",
        "  * Lấy Output shape của một Keras Layer:\n",
        "  ```\n",
        "  layer.output_shape\n",
        "  ```\n",
        "\n",
        "> **LƯU Ý**: cú pháp lấy Input, Input shape và Output, Output shape áp dụng được với mọi layers thuộc package keras.layers\n",
        "\n",
        "### Tham khảo\n",
        "Các em có thể tham khảo thêm về Keras Dense layer tại [đây](https://keras.io/layers/core/#dense) và tham khảo về Keras Layer tại [đây](https://keras.io/layers/about-keras-layers/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJS8ipEFqQQD",
        "colab_type": "text"
      },
      "source": [
        "## Input\n",
        "Chúng ta đã có được hình dung cơ bản về cấu trúc của một Keras Layer. Bây giờ chúng ta sẽ tiếp tục tìm hiểu một layer rất cơ bản nữa của Keras - Input layer\n",
        "### Khai báo một Input layer\n",
        "Dưới đây là cách khai báo duy nhất của một Input layer 2 chiều (gồm 32x32 phần tử)\n",
        "```\n",
        "# import layer từ Keras\n",
        "from keras.layers import Input\n",
        "\n",
        "inp = Input(shape=(32, 32), name='input')\n",
        "```\n",
        "Do Input layer không có layer nào trước nó nên không cách khai báo 2 của Dense layer không được chấp nhận ở đây. Tuy nhiên, kiểu trả về của hàm khởi tạo Input() là một **Keras Tensor**, không phải một Keras Layer (như cách khai báo 1 của Dense layer), nói cách khác inp là một Keras Tensor\n",
        "> **LƯU Ý**:\n",
        "  * Tham số shape ở hàm khởi tạo không bao gồm batch size. Nói cách khác, shape không có dạng (batch_size, input_shape[1], ..., input_shape[n]) mà chỉ có dạng (input_shape[1], ..., input_shape[n]) \n",
        "  * Nếu muốn khai Input layer 1 chiều thì shape phải có dạng (input_size, ). Ví dụ:\n",
        "  ```\n",
        "  inp = Input(shape=(32,), name='input')\n",
        "  ```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B77oC88tE_dU",
        "colab_type": "text"
      },
      "source": [
        "## Các core layers khác\n",
        "### Activation\n",
        "**Activation layer**: một layer có dạng $a = g(x)$. Nói cách khác, Activation layer chỉ có activation function, không có các tham số (như $W, b$ của Dense layer)\n",
        "\n",
        "**Khai báo Activation layer**: dưới đây là hai cách khai báo Activation layer với activation function là hàm ReLU. Kiểu trả về của hai cách khai báo Activation layer tương tự như kiểu trả về của hai cách khai báo Dense layer.\n",
        "  * **Cú pháp 1**:\n",
        "  ```\n",
        "  from keras.layers import Activation\n",
        "  \n",
        "  layer = Activation(activation='relu')\n",
        "  ```\n",
        "  * **Cú pháp 2**:\n",
        "  ```\n",
        "  from keras.layers import Activation\n",
        "  \n",
        "  cur_output = Activation(activation='relu')(prev_output)\n",
        "  ```\n",
        "**LƯU Ý**: Input và Output của Activation layer có shape tương tự như Input và Output của Dense layer. Tổng quát hơn, trong Keras, dimension đầu tiên của các Tensors đều là batch_size  \n",
        "\n",
        "### Flatten\n",
        "**Flatten layer**: một layer có Input là Output của layer liền trước và Output là flattened version của Input. Flattened version của một Tensor với shape (size[1], ..., size[n]) là một Vector với shape (size[1] \\* ... \\* size[n], )\n",
        "\n",
        "**Khai báo Flatten layer**:\n",
        "* **Cú pháp 1**:\n",
        "\n",
        "```\n",
        "from keras.layers import Flatten\n",
        "\n",
        "layer = Flatten()\n",
        "```\n",
        "\n",
        "* **Cú pháp 2**:\n",
        "\n",
        "```\n",
        "from keras.layers import Flatten\n",
        "\n",
        "cur_output = Flatten()(prev_output)\n",
        "```\n",
        "**NHẮC LẠI**: Input của Flatten layer có shape (batch_size, size[1], ..., size[n]) và Output có shape (batch_size, size[1] \\* ... \\* size[n])\n",
        "### Reshape\n",
        "**Reshape layer**: generalized version của Flatten layer. Cụ thể, Reshape layer sẽ có reshape Input thành shape mà chúng ta mong muốn.\n",
        "\n",
        "**Khai báo Reshape layer**:\n",
        "  * **Cú pháp 1**:\n",
        "  ```\n",
        "  from keras.layers import Reshape\n",
        "  \n",
        "  layer = Reshape(target_shape=(32, 32))\n",
        "  ```\n",
        "  \n",
        "  * **Cú pháp 2**:\n",
        "  ```\n",
        "  from keras.layers import Reshape\n",
        "  \n",
        "  cur_output = Reshape(target_shape=(32, 32))(prev_output)\n",
        "  ```\n",
        "  \n",
        "### Các core layers khác\n",
        "Các em có thể tự tìm hiểu thêm các core layers của Keras tại [đây](https://keras.io/layers/core/).\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfRjNEA6ho06",
        "colab_type": "text"
      },
      "source": [
        "# KERAS MODELS\n",
        "Ở phần này, chúng ta sẽ học cách build một deep learning model cơ bản bằng Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld5419D1ii3T",
        "colab_type": "text"
      },
      "source": [
        "## Build model\n",
        "### Build model bằng Sequential model\n",
        "Trước hết chúng ta đi vào dạng model cơ bản nhất của Deep learning - Sequential model\n",
        "\n",
        "**Sequential model**: là model gồm các layers chồng lên nhau, tạo thành một stack. Dưới đây là một ví dụ về sequential model.\n",
        "\n",
        "![Sequential model](http://www.samyzaf.com/ML/pima/nn6.png =600x300)\n",
        "\n",
        "Dưới đây là một non-sequential model (các layers tạo thành cấu trúc cây, không phải stack)\n",
        "\n",
        "![Non-sequential mode](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_5/GoogleNet.png =650x300)\n",
        "\n",
        "**Khởi tạo một sequential model**:\n",
        "  * **LƯU Ý**: ta cần import class **keras.models.Sequential** trước khi khai báo một Sequential model \n",
        "\n",
        "Ta hãy xem hai cách khai báo một model với 3 layers (1 Input layer, 1 Hidden layer và 1 Output layer):\n",
        "```\n",
        "# import packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# cú pháp 1\n",
        "model = Sequential([\n",
        "  Dense(units=16, activation='relu', input_shape=(32,))\n",
        "  Dense(units=8, activation='softmax')\n",
        "])\n",
        "\n",
        "# cú pháp 2\n",
        "model = Sequential()\n",
        "model.add(Dense(units=16, activation='relu', input_shape=(32,)))\n",
        "model.add(Dense(units=8, activation='softmax'))\n",
        "```\n",
        "\n",
        "**Cú pháp 1**: ta khởi tạo một Sequential model với 1 Input layer (1 vector 32 chiều), 1 Hidden layer (Dense layer với 16 neurons và activation function ReLU) và 1 Output layer (Dense layer với 8 neurons và activation function Softmax) bằng cách truyền 1 list các layers vào hàm khởi tạo.\n",
        "  * **Input layer**: chắc các em sẽ thắc mắc tại sao layer đầu tiên trong layer list lại là Dense layer mà không phải Input layer. Điều này là do cơ chế hoạt động của Sequential model, xin nhắc lại là Sequential model là *một stack các layers* trong khi Input layer lại trả về một Keras Tensor nên Input layer không được include trong layer list dù nó là layer đầu tiên của model. Thay vì sử dụng Input layer, ta thêm tham số *input_shape* vào hàm khởi tạo của layer đầu tiên trong layer list để xác định Input shape của model.\n",
        "\n",
        "**Cú pháp 2**: đầu tiên, ta khởi tạo một Sequential model rỗng sau đó lần lượt thêm các layer vào model bằng phương thức *add()*\n",
        "  * **LƯU Ý**: nếu các em build một Sequential model bằng cú pháp 1, các em vẫn có thể sử dụng phương thức *add()* để chồng thêm layer vào layer list\n",
        "\n",
        "Các em có thể tham khảo thêm về Sequential model tại [đây](https://keras.io/models/sequential/)\n",
        "\n",
        "### Build model bằng functional API\n",
        "Ở phần này chúng ta sẽ làm quen với functional API của Keras, một công cụ giúp ta tạo được các models phức tạp hơn so với Sequential model. Cụ thể, functional API cho phép ta tạo được các sequential models và cả non-sequential models\n",
        "\n",
        "**Khởi tạo một model bằng functional API**:\n",
        "  * **LƯU Ý**: ta cần import class **keras.models.Model** trước khi sử dụng functional API để tạo model\n",
        "Ta hãy xem cách khởi tạo model giống với ví dụ ở phần Sequential model (3 layers - Input layer, 1 Hidden layer và Output layer)\n",
        "\n",
        "```\n",
        "# import packages\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "\n",
        "input = Input(shape=(32,))\n",
        "hidden = Dense(units=16, activation='relu')(input)\n",
        "output = Dense(units=8, activation='softmax')(hidden)\n",
        "\n",
        "model = Model(input, output)\n",
        "```\n",
        "\n",
        "Nếu ở Sequential model, ta tập trung vào các layers thì trong functional API, ta tập trung vào các tensors. Cụ thể, ta khởi tạo input tensor với shape (32, ) sau đó khởi tạo output tensor của hidden layer, cuối cùng là khởi tạo output tensor của output layer. Phương thức *Model()* được truyền vào 2 tham số là input tensor và output tensor của model cần tạo.\n",
        "\n",
        "Các em có thể tham khảo thêm về functional API tại [đây](https://keras.io/models/model/)\n",
        "\n",
        "> ***Tips***: sau khi build xong model, chúng ta có thể sử dụng lệnh *print(model.summary())* để in ra cấu trúc của model, giúp kiểm tra cấu trúc của model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo9hL6cd9QJT",
        "colab_type": "text"
      },
      "source": [
        "## Train model\n",
        "### Compile model\n",
        "Dù ta khai báo một Sequential model hay một model sử dụng funtional API, ta đều cần *compile* model trước khi huấn luyện\n",
        "\n",
        "**Compile model**: compile có thể hiểu là ta cấu hình lại model để chuẩn bị cho quá trình huấn luyện (VD: set up thuật toán tối ưu, loss function, hàm đánh giá, etc)\n",
        "\n",
        "**Cú pháp**: giả sử ta cần tạo một model để phục vụ cho một classification task\n",
        "```\n",
        "# import packages\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "# Giả sử ta đã khởi tạo một model 'model' bằng Sequential model hoặc functional API\n",
        "model.compile(\n",
        "  optimizer=SGD(),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "```\n",
        "\n",
        "Đoạn code trên có nghĩa là model của chúng ta sẽ được huấn luyện bằng thuật toán *Stochastic Gradient Descent (SGD)* với loss function là hàm *categorical crossentropy* và được đánh giá dựa trên *độ chính xác (accuracy)*\n",
        "\n",
        "**Các thuật toán huấn luyện (optimizers) trong Keras**:\n",
        "  * Stochastic Gradient Descent (SGD): thuật toán gradient descent quen thuộc trong machine learning (xem code mẫu ở trên)\n",
        "  * AdaGrad: một biến thể của SGD với learning rate có thể được tự động điều chỉnh để tránh việc thuật toán rơi vào local minima. Dưới đây là code mẫu\n",
        "\n",
        "```\n",
        "... # everything has been imported\n",
        "from keras.optimizers import Adagrad\n",
        "\n",
        "\n",
        "model.compile(\n",
        "  optimizer=SGD(),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "  ```\n",
        "\n",
        "  * Adam: một biến thể khác của SGD với learning rate tự động điều chỉnh như AdaGrad. Đây là thuật toán phổ biến nhất hiện nay do tốc độ huấn luyện và khả năng hội tụ tốt, tránh được local minima.. Dưới đây là code mẫu\n",
        "\n",
        "```\n",
        "... #every has been imported\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "  optimizer=Adam(),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "```\n",
        "\n",
        "Các em có thể tham khảo thêm tại [đây](https://keras.io/optimizers/)\n",
        "\n",
        "**Các loss function trong Keras**:\n",
        "  * mean_squared_error: loss function thông dụng nhất cho các Regression tasks\n",
        "  * binary_crossentropy: loss function thông dụng nhất cho các Binary Classification tasks (Classification tasks với 2 classes)\n",
        "  * categorical_crossentropy: loss function thông dụng nhất cho các Classification tasks với 3 classes trở lên\n",
        "\n",
        "Các em có thể tham khảo thêm tại [đây](https://keras.io/losses/)\n",
        "\n",
        "**Các hàm đánh giá (metrics) trong Keras**:\n",
        "  * accuracy: thông dụng đối với các Classification tasks\n",
        "\n",
        "Các em có thể tham khảo thêm tại [đây](https://keras.io/metrics/)\n",
        "\n",
        "### Train model\n",
        "**Các khái niệm cơ bản**:\n",
        "  * **Epoch**: trong machine learning, 1 epoch được tính là 1 lần model của chúng ta được train trên toàn bộ tập huấn luyện\n",
        "  * **Batch size**: số training examples được sử dụng cho 1 bước Gradient Descent\n",
        "\n",
        "**Train model**: giả sử ta có tập huấn luyện (x_train, y_train) và tập validation (x_val, y_val). \n",
        "  Ta có thể train model như sau:\n",
        "  \n",
        "  ```\n",
        "  ... # everything has been imported\n",
        "  from keras.callbacks import LambdaCallback # LambdaCallback được import để lưu lại model (xem đoạn code ở dưới)\n",
        "  \n",
        "  model.fit(\n",
        "    x=x_train, # training features\n",
        "    y=y_train, # training targets\n",
        "    batch_size=64,\n",
        "    epochs=100,\n",
        "    validation_data=(x_val, y_val) # validation features & validation targets,\n",
        "    callbacks=[\n",
        "      # dòng này được dùng để lưu lại model sau mỗi bước train\n",
        "      LambdaCallback(on_train_end=lambda logs: model.save(model_final)\n",
        "    ]\n",
        "  )\n",
        "  ```\n",
        "\n",
        "Nếu ta \"lười\" hoặc không có tập (x_val, y_val) thì có thể thay *validation_data* bằng *validation_split*. Cụ thể, nếu *validation_split* = 0.2 thì Keras sẽ lấy 20% số examples từ (x_train, y_train) để làm tập validation\n",
        "\n",
        "  * **LƯU Ý**: dimension đầu tiên của x_train và y_train phải là n_samples (VD: x_train có thể có shape là (n_samples, x_shape[0], ..., x_shape[n]) chứ không được là (x_shape[0], ..., x_shape[n]))\n",
        "\n",
        "Các em có thể tham khảo thêm tại [đây](https://keras.io/models/model/#fit)\n",
        "\n",
        "**Đánh giá model**: giả sử ta có tập test (x_test, y_test). Ta có thể đánh giá model như sau:\n",
        "\n",
        "```\n",
        "loss = model.evaluate(\n",
        "  x=x_test,\n",
        "  y=y_test,\n",
        "  batch_size=64\n",
        ")\n",
        "# loss sẽ nhận giá trị là test loss (và giá trị của hàm đánh giá, nếu có) của model dựa trên tập test\n",
        "```\n",
        "\n",
        "Các em có thể tham khảo thêm tại [đây](https://keras.io/models/model/#evaluate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mcWj1fqKOJT",
        "colab_type": "text"
      },
      "source": [
        "## Sử dụng model\n",
        "### Lưu lại model để sử dụng hoặc train tiếp sau này\n",
        "\n",
        "```\n",
        "model.save(model_path)\n",
        "```\n",
        "\n",
        "### Load model\n",
        "\n",
        "```\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(model_path)\n",
        "```\n",
        "\n",
        "### Sử dụng model để dự đoán kết quả\n",
        "```\n",
        "pred = model.predict(\n",
        "  x=x_new,\n",
        "  batch_size=64\n",
        ")\n",
        "```\n",
        "\n",
        "  * **LƯU Ý**: pred sẽ có shape là (n_samples, output_shape[1], ..., output_shape[n])\n",
        "\n",
        "Các em có thể tham khảo thêm tại [đây](https://keras.io/models/model/#predict)\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1mxvlfUIoZV",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional neural networks - CNN (advanced)\n",
        "## Convolutional layer\n",
        "Ở phần trên, chúng ta đã làm quen với cách tạo một fully-connected neural net (dạng neural net cơ bản). Trong phần này, chúng ta sẽ làm quen với convolutional neural nets (CNN), một công cụ được sử dụng phổ biến trong xử lý ảnh.\n",
        "\n",
        "**Ví dụ mở đầu**: trước hết ta đi vào một ví dụ đơn giản. Giả sử ta có layer $L_1$ và $L_2$ nối tiếp nhau trong một mạng neuron $N$. Nếu $L_1$ có  $n_1$ neurons và $L_2$ có $n_2$ neurons thì tham số $W_2$ phải có $n_1 * n_2$ phần tử (nếu liên kết giữa $L_1$ và $L_2$ là fully-connected). \n",
        "\n",
        "$\\rightarrow$ Nếu $L_1$ là một ảnh Input dạng RGB với shape là (64, 64, 3) và $L_2$ là một Tensor với shape là (32, 32, 16) thì số phần tử của $W_2$ sẽ là $64*64*3*32*32*16 = 201326592$. Một con số rất lớn ! Thử hỏi với ảnh kích cỡ lớn hơn thì chỉ có máy tính lượng tử mới có thể tải nổi mất !\n",
        "\n",
        "Để tạo điều kiện cho những người không có tiền nhưng vẫn muốn học machine learning. Người ta đã phát minh ra một kiểu model mới - convolutional neural nets.\n",
        "\n",
        "**Ý tưởng của convolutional neural nets**: thay vì mỗi neuron của $L_2$ được tạo nên bởi tất cả neurons của $L_1$, người ta chỉ lấy một vài neurons của $L_1$ để tạo ra 1 neuron của $L_2$. Mô hình layer như vừa rồi được gọi là **convolutional layer**. Hãy xem minh hoạ dưới đây để hiểu cách hoạt động của convolutional layer.\n",
        "\n",
        "![Convolutional layer](https://cdn-images-1.medium.com/max/1000/0*qehV5z77wj2cbHBM.)\n",
        "\n",
        "Trong hình vẽ trên, $L_1$ có shape (4, 4, 1), $L_2$ có shape (2, 2, 1) và mỗi neuron của $L_2$ được tạo nên bởi $3 * 3 = 9$ neurons của $L_1$, thay vì tất cả $4 * 4 = 16$ neurons như mạng neuron thông thường.\n",
        "\n",
        "Hãy xem một hình ảnh khác để hình dung rõ hơn.\n",
        "\n",
        "![Convolutional layer](https://cdn-images-1.medium.com/max/1600/1*BSLjlJf31gj98ABJMCt3-g@2x.png =500x300)\n",
        "\n",
        "Nếu ở ví dụ trên, $L_1$ và $L_2$ đều có dimension 3 là 1 thì ví dụ này tổng quát hơn, $L_1$ có shape là (32, 32, 3) và $L_2$ có shape là (32, 32, 10). Hình vẽ thể hiện rằng mỗi neuron của $L_2$ được tạo nên bởi $5 * 5 * 3 = 75$ neurons của $L_1$. \n",
        "\n",
        "Vậy lượng tham số cần sử dụng ở đây là bao nhiêu ? Hãy tìm hiểu cách convolutional layer tạo nên 1 neuron của layer $L_2$. Cụ thể, mỗi phần tử trong block màu đỏ 5x5x3 sẽ được nhân với một số thực (tham số), sau đó convolutional layer lấy tổng của 5x5x3 giá trị đó làm giá trị của neuron hình tròn trong hình vẽ. Vậy, với mỗi neuron của $L_2$, ta cần đến 5x5x3 tham số. Thú vị ở chỗ, 5x5x3 tham số này sẽ được sử dụng bởi mọi neuron trong 1 channel (1 channel trong ví dụ trên là 1 Tensor với shape (32, 32, 1), như vậy $L_2$ có 10 channels), thay vì mỗi neuron trong 1 channel sẽ có một bộ 5x5x3 tham số riêng của nó. Vậy thì ta sẽ cần tổng cộng là 5x5x3 tham số cho mỗi channel và 5x5x3x10 tham số cho cả 10 channels của $L_2$.\n",
        "\n",
        "Nếu sử dụng fully-connected layers trong trường hợp vừa rồi thì giữa $L_1$ và $L_2$ sẽ cần tới 32x32x3x32x32x10. So với 5x5x3x10 tham số khi sử dụng convolutional layer thì fully-connected layers quả thật rất tốn bộ nhớ.\n",
        "\n",
        "> **LƯU Ý**: mỗi bộ tham số 5x5x3x10 giữa $L_1$ và $L_2$ được gọi là kernel, theo thuật ngữ của convolutional layer\n",
        "\n",
        "**Một chút nữa về convolutional layer**: các bạn sẽ thắc mắc tại sao người ta không dùng convolutional layers hết đi cho tiết kiệm mà cứ phải dùng fully-connected layers đúng không ? Như các bạn thấy, 1 neuron của $L_2$ chỉ được tạo nên bởi 1 lượng nhỏ các neurons lân cận nhau của $L_1$. Trong xử lý ảnh, làm gì có chiếc xe đạp nào mà bánh một nơi, thân một nơi, yên xe một nơi đúng không. Đó chính là lý do convolutional layer được sử dụng nhiều trong xử lý ảnh. Xét trong trường hợp tổng quát, giả sử ta có một vector $x$ với mô tả các thông tin khác nhau của một đối tượng, chắc gì các phần tử lân cận nhau trong $x$ đã đủ để neural net học được một cái gì đó hoàn chỉnh. Ví dụ, nếu $x$ là (math_score, physic_score, chemist_score) thì để học được xem liệu học sinh được mô tả bởi $x$ có khả năng đỗ đại học hay không thì không thể áp dụng convolutional layer với (math_score, physic_score) rồi lại (physic_score, chemist_score) được mà ta phải sử dụng fully-connected layer để học được thông tin từ cả 3 phần tử trong $x$.\n",
        "\n",
        "## Pooling layer\n",
        "Pooling layer là một kiểu layer khác được sử dụng cùng với convolutional layer trong CNN. Mục đích của pooling layer là làm giảm số tham số cần dùng của model. \n",
        "\n",
        "**Ý tưởng của pooling layer**: với mỗi channel, pooling layer sẽ tập hợp thông tin của các neurons lân cận nhau và cho ra một \"summary neuron\". Ưu điểm của pooling layer là thu gọn kích cỡ của Tensor input mà không cần sử dụng một tham số nào. Hãy xem hình ảnh dưới đây. \n",
        "\n",
        "![Pooling layer](https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png =500x300)\n",
        "\n",
        "Trong hình ảnh trên, pooling layer tập hợp thông tin của mỗi block 2x2 trong channel bằng cách output ra neuron có giá trị lớn nhất trong block đó. Đây là một kĩ thuật pooling rất phổ biến và đã giúp CNN làm mưa làm gió trong những năm vừa qua. Kĩ thuật này gọi là Max Pooling.\n",
        "\n",
        "Nhắc lại rằng, pooling layer sẽ hoạt động trên các channel một cách độc lập. Neurons của channel này sẽ không liên quan đến kết quả pooling của channel khác.\n",
        "\n",
        "## Strides và Padding\n",
        "**Padding**: padding thực chất là bao quanh input tensor bằng các phần tử có giá trị 0. Hãy xem hình vẽ dưới đây để hình dung rõ hơn.\n",
        "\n",
        "![Padding](http://deeplearning.net/software/theano/_images/arbitrary_padding_no_strides.gif =400x400)\n",
        "\n",
        "Các phần tử màu xanh dương là các phần tử của input tensor, các phần tử màu trắng là các phần tử được padding vào input tensor.\n",
        "\n",
        "Giống như pooling, padding hoạt động trên từng channel một cách độc lập. Ta không thể padding theo channel mà chỉ có thể padding theo chiều dài và chiều rộng của input tensor. \n",
        "\n",
        "Công dụng của padding là giúp tuỳ ý điều chỉnh chiều dài và chiều rộng của output tensor. Nói cách khác, ta có thể thoải mái set pooling size (của pooling layer) và kernel size (của convolutional layer) mà không cần quan tâm kích cỡ của output tensor (vì đã có padding lo rồi).\n",
        "\n",
        "Có hai kiểu padding phổ biến là SAME padding và VALID padding.\n",
        "  * **SAME padding**: padding sao cho input tensor và output tensor của layer có cùng chiều dài và chiều rộng\n",
        "  * **VALID padding**: không áp dụng padding\n",
        "\n",
        "**Strides**: xét hình vẽ dưới đây:\n",
        "\n",
        "![No strides](https://cdn-images-1.medium.com/max/1000/0*qehV5z77wj2cbHBM.)\n",
        "\n",
        "Ta thấy rằng, kernel sẽ dịch chuyển từng ô một (theo chiều dài và chiều rộng). Strides thực chất là điểu chính kích cỡ bước nhảy của kernel. Cụ thể, hãy xem hình dưới đây:\n",
        "\n",
        "![Strides](http://deeplearning.net/software/theano/_images/numerical_padding_strides.gif =400x300)\n",
        "\n",
        "Ở đây, ta áp dụng strides (2, 2), tức là kernel sẽ nhảy 2 ô 1 lần (theo chiều dài và chiều rộng). Nếu ta lấy strides là (2, 3) thì kernel sẽ nhảy 2 ô 1 lần theo chiều dài và 3 ô 1 lần theo chiều rộng.\n",
        "\n",
        "Giống như padding, strides hoạt động trên từng channel một cách độc lập, ta chỉ có thể điều chỉnh kích cỡ bước nhau theo chiều dài và chiều rộng, không thể \"nhảy\" theo channel được.\n",
        "\n",
        "Công dụng của strides là giúp convolutional layer tránh học nhiều lần cùng 1 feature trong input tensor. Cụ thể, nếu ta chụp hình cái xe đạp và khoanh vùng nó bằng một ô vuông thì nếu ta dịch ô vuông đấy đi một vài pixels thì nó vẫn chứa gần như toàn bộ cái xe đạp.\n",
        "\n",
        "Các em có thể tìm hiểu kĩ hơn về CNN tại [đây](http://www.deeplearningbook.org/contents/convnets.html)\n",
        "\n",
        "## Convolutional neural nets trong Keras\n",
        "**Convolutional layer**: ta có thể khai báo một convolutional layer trong Keras như sau:\n",
        "\n",
        "```\n",
        "# import packages\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "# cú pháp 1: trả về Keras Layer\n",
        "conv = Conv2D(\n",
        "  filters=10\n",
        "  kernel_size=(3, 3)\n",
        "  strides=(2, 2)\n",
        "  padding='same'\n",
        ")\n",
        "\n",
        "# cú pháp 2: trả về Keras Tensor\n",
        "conv_out = Conv2D(\n",
        "  filters=10,\n",
        "  kernel_size=(3, 3)\n",
        "  strides=(2, 2)\n",
        "  padding='same'\n",
        ")(conv_inp)\n",
        "```\n",
        "\n",
        "Cả hai cú pháp trên giúp build một convolutional layer với số output channels là 10, chiều dài và rộng của kernel là (3, 3), bước nhảy strides theo chiều dài và rộng của input tensor là (2, 2) và kiểu padding là SAME padding.\n",
        "\n",
        "Các em có thể tham khảo thêm tại [đây](https://keras.io/layers/convolutional/#conv2d)\n",
        "\n",
        "**Max pooling layer**: ta có thể khai báo một max pooling layer trong Keras như sau:\n",
        "\n",
        "```\n",
        "# import packages\n",
        "from keras.layers import MaxPooling2D\n",
        "\n",
        "# cú pháp 1: trả về Keras Layer\n",
        "maxpool = MaxPooling2D(\n",
        "  pool_size=(2, 2),\n",
        ")\n",
        "\n",
        "# cú pháp 2: trả về Keras Tensor\n",
        "maxpool_out = MaxPooling2D(\n",
        "  pool_size=(2, 2)\n",
        ")(maxpool_inp)\n",
        "```\n",
        "\n",
        "Cả hai có pháp trên giúp build một Max Pooling layer với pooling size (kích cỡ của một block được tổng hợp thông tin) là (2, 2).\n",
        "\n",
        "Các em có thể tham khảo thêm tại [đây](https://keras.io/layers/pooling/#maxpooling2d)\n",
        "\n",
        "## Cấu trúc một mạng CNN\n",
        "Dưới đây là một mạng CNN hoàn chỉnh\n",
        "\n",
        "![CNN](https://cdn-images-1.medium.com/max/1558/1*N4h1SgwbWNmtrRhszM9EJg.png)\n",
        "\n",
        "Trong một mạng CNN, các layers đầu tiên sẽ là convolutional layers và pooling layers. Các layers đầu tiên này được gọi là feature extractor, do chúng có nhiệm vụ học các đặc trưng của ảnh. Sau feature extractor sẽ là các fully-connected layers giúp đưa ra dự đoán dựa trên các đặc trưng học được.\n",
        "\n",
        "Để chuyển tiếp từ feature extractor sang fully-connected, ta phải flatten output tensor của feature extractor bằng Flatten layer của Keras. Sau đó sẽ build phần fully-connected với input là flattened output của feature extractor.\n",
        "\n",
        "Dưới đây là một mạng CNN đơn giản bằng Keras:\n",
        "\n",
        "```\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# input image là một ảnh RGB (3 channels) với kích cỡ 64x64\n",
        "input = Input(shape=(64, 64, 3))\n",
        "\n",
        "model = Conv2D(\n",
        "  filters= 16, \n",
        "  kernel_size=(3, 3),\n",
        "  strides=(2, 2),\n",
        "  padding='same',\n",
        "  activation='relu'\n",
        ")(input)\n",
        "\n",
        "model = MaxPooling2D(\n",
        "  pool_size=(2, 2)\n",
        ")(model)\n",
        "\n",
        "model = Flatten()(model)\n",
        "\n",
        "model = Dense(\n",
        "  units=4,\n",
        "  activation='softmax'\n",
        ")(model)\n",
        "\n",
        "model = Model(input, model)\n",
        "\n",
        "model.compile(\n",
        "  optimizer=Adam(),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(model.summary())\n",
        "```"
      ]
    }
  ]
}